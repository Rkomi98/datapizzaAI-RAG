# Setup e Utilizzo del Chatbot RAG Datapizza-AI

## ðŸ“‹ Prerequisiti

1. **Python 3.13+** (giÃ  configurato nel virtual environment)
2. **Qdrant Vector Database**
3. **OpenAI API Key**

## ðŸš€ Setup Completo

### 1. Attivare l'environment virtuale

```bash
source rag/bin/activate
```

### 2. Installare le dipendenze (se necessario)

```bash
pip install -r requirements.txt
```

### 3. Configurare le variabili d'ambiente

Crea un file `.env` nella root del progetto:

```bash
cp .env.example .env
```

Modifica il file `.env` e inserisci la tua OpenAI API Key:

```
OPENAI_API_KEY=sk-proj-...
```

### 4. Avviare Qdrant

Puoi avviare Qdrant usando Docker:

```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

Oppure scarica e avvia Qdrant localmente da: https://qdrant.tech/documentation/quick-start/

### 5. Eseguire l'Ingestion delle FAQ

Prima di usare il chatbot, devi processare e ingerire i documenti FAQ:

```bash
python ingest_faq.py
```

Questo script:
- Legge i file `datapizza_faq.md` e `FAQ_Video.md`
- Li processa e divide in chunks
- Genera embeddings con OpenAI
- Li salva nel vector store Qdrant

Output atteso:
```
============================================================
ðŸš€ Inizio ingestion delle FAQ Datapizza-AI
============================================================

ðŸ“¦ Setup vector store...
âœ“ Collection 'datapizza_faq' creata con successo

ðŸ”§ Creazione pipeline di ingestion...

ðŸ“š Ingestion documenti...
ðŸ“„ Processando datapizza_faq.md...
âœ“ datapizza_faq.md processato con successo
ðŸ“„ Processando FAQ_Video.md...
âœ“ FAQ_Video.md processato con successo

âœ… Ingestion completata!
============================================================
```

### 6. Avviare il Chatbot

```bash
python chatbot_faq.py
```

## ðŸ’¬ Utilizzo del Chatbot

Una volta avviato, il chatbot entrerÃ  in modalitÃ  interattiva:

```
======================================================================
ðŸ¤– Chatbot FAQ Datapizza-AI
======================================================================
Fai le tue domande su Datapizza-AI!
Digita 'exit', 'quit' o 'esci' per terminare.
======================================================================

ðŸ‘¤ Tu: Come si differenzia Datapizza-AI da Langchain?

ðŸ¤– Bot: La differenza principale Ã¨ il diverso livello di astrazione...
```

### Esempi di Domande

- "Cosa differenzia Datapizza-AI da Langchain?"
- "Supporta modelli Llama?"
- "Come funziona la gestione della memory?"
- "Posso usare documenti aziendali in locale?"
- "Quali sono i casi d'uso concreti?"

## ðŸ”§ Troubleshooting

### Errore: "OPENAI_API_KEY non trovata"
Assicurati di aver creato il file `.env` e inserito la tua API key.

### Errore: "Connection refused" (Qdrant)
Verifica che Qdrant sia in esecuzione su `localhost:6333`

### Errore: "Collection not found"
Esegui prima lo script di ingestion: `python ingest_faq.py`

### Il chatbot risponde sempre "Non sono ancora state fatte domande a riguardo"
Possibili cause:
1. L'ingestion non Ã¨ stata eseguita correttamente
2. La soglia di similarity Ã¨ troppo alta
3. La domanda Ã¨ troppo generica o fuori topic

## ðŸ“š Struttura del Progetto

```
.
â”œâ”€â”€ datapizza_faq.md           # FAQ generali
â”œâ”€â”€ FAQ_Video.md               # FAQ da video
â”œâ”€â”€ ingest_faq.py              # Script per ingestion
â”œâ”€â”€ chatbot_faq.py             # Chatbot interattivo
â”œâ”€â”€ requirements.txt           # Dipendenze Python
â”œâ”€â”€ .env                       # Configurazione (da creare)
â”œâ”€â”€ .env.example              # Template configurazione
â””â”€â”€ setup_instructions.md      # Questo file
```

## ðŸŽ¯ Come Funziona

### Pipeline di Ingestion
1. **TextParser**: Legge i file markdown
2. **NodeSplitter**: Divide il testo in chunks di max 1000 caratteri
3. **ChunkEmbedder**: Genera embeddings con OpenAI (text-embedding-3-small)
4. **QdrantVectorstore**: Salva chunks ed embeddings nel database

### Pipeline di Retrieval (DagPipeline)
1. **ToolRewriter**: Riscrive la query per migliorare il retrieval
2. **OpenAIEmbedder**: Genera embedding della query
3. **QdrantVectorstore**: Recupera i chunks piÃ¹ simili
4. **ChatPromptTemplate**: Formatta prompt con contesto recuperato
5. **OpenAIClient**: Genera la risposta finale (gpt-4o-mini)

## ðŸ”’ Note sulla Privacy

- Le query e i documenti vengono inviati a OpenAI per generare embeddings e risposte
- Se necessiti di privacy completa, considera l'uso di modelli locali (Llama/Mistral)
- Qdrant puÃ² essere configurato con persistenza su disco per non perdere i dati

## ðŸ“– Risorse

- [Documentazione Datapizza-AI](https://docs.datapizza.ai/)
- [Guida RAG](https://docs.datapizza.ai/0.0.2/Guides/RAG/rag/)
- [Qdrant Documentation](https://qdrant.tech/documentation/)

