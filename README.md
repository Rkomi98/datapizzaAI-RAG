# Chatbot RAG FAQ Datapizza-AI

Un chatbot RAG intelligente che risponde alle domande frequenti su Datapizza-AI, costruito utilizzando il framework datapizza-ai.

## ğŸ¯ Descrizione

Questo progetto implementa un sistema RAG (Retrieval-Augmented Generation) completo che:
- **Analizza** le FAQ su Datapizza-AI contenute in file markdown
- **Risponde** alle domande degli utenti basandosi esclusivamente sulle informazioni nelle FAQ
- **Restituisce** un messaggio specifico quando non trova informazioni rilevanti: "Non sono ancora state fatte domande a riguardo."

## âœ¨ Caratteristiche

- ğŸ” **Retrieval semantico** con embeddings OpenAI
- ğŸ§  **Query rewriting** per migliorare il retrieval
- ğŸ’¾ **Vector store** Qdrant per memorizzazione efficiente
- ğŸ¤– **Generazione risposte** con GPT-4o-mini
- ğŸ’¬ **Interfaccia interattiva** da terminale
- ğŸ“ **Pipeline modulare** facilmente estensibile

## ğŸ—ï¸ Architettura

### Pipeline di Ingestion
```
File Markdown â†’ TextParser â†’ NodeSplitter â†’ ChunkEmbedder â†’ Qdrant VectorStore
```

### Pipeline di Retrieval (DagPipeline)
```
Query Utente â†’ ToolRewriter â†’ Embedder â†’ VectorStore Retrieval â†’ Prompt Template â†’ Generator (GPT-4o-mini)
```

## ğŸš€ Quick Start

### 1. Attiva l'environment virtuale

```bash
source rag/bin/activate
```

### 2. Installa le dipendenze (se necessario)

```bash
pip install -r requirements.txt
```

### 3. Configura le variabili d'ambiente

Crea un file `.env` e inserisci la tua OpenAI API key:

```bash
cp .env.example .env
# Modifica .env e inserisci la tua API key
```

### 4. Avvia Qdrant

```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

### 5. Verifica il setup

```bash
python test_setup.py
```

### 6. Esegui l'ingestion delle FAQ

```bash
python ingest_faq.py
```

### 7. Avvia il chatbot

```bash
python chatbot_faq.py
# oppure usa lo script bash
./run_chatbot.sh
```

## ğŸ’¡ Esempi di Utilizzo

```
ğŸ‘¤ Tu: Cosa differenzia Datapizza-AI da Langchain?

ğŸ¤– Bot: La differenza principale con altri framework Ã¨ il diverso livello 
di astrazione dei moduli. Langchain usa astrazioni troppo elevate che non 
permettono di uscire facilmente dai binari imposti...

ğŸ‘¤ Tu: Supporta modelli open-source?

ğŸ¤– Bot: SÃ¬, il framework supporta anche modelli Llama. Nella documentazione 
su docs.datapizza.ai puoi trovare le istruzioni per eseguire un client 
Llama o un server Llama in locale...

ğŸ‘¤ Tu: Che cos'Ã¨ la fotosintesi clorofilliana?

ğŸ¤– Bot: Non sono ancora state fatte domande a riguardo.
```

## ğŸ“ Struttura del Progetto

```
datapizzaAI-RAG/
â”œâ”€â”€ datapizza_faq.md          # FAQ generali su Datapizza-AI
â”œâ”€â”€ FAQ_Video.md              # FAQ estratte da video tutorial
â”œâ”€â”€ ingest_faq.py             # Script per processare e ingerire FAQ
â”œâ”€â”€ chatbot_faq.py            # Chatbot RAG interattivo
â”œâ”€â”€ test_setup.py             # Script per verificare il setup
â”œâ”€â”€ run_chatbot.sh            # Script bash per avviare il chatbot
â”œâ”€â”€ requirements.txt          # Dipendenze Python
â”œâ”€â”€ .env                      # Configurazione (da creare)
â”œâ”€â”€ .env.example              # Template per configurazione
â”œâ”€â”€ setup_instructions.md     # Istruzioni dettagliate
â””â”€â”€ README.md                 # Questo file
```

## ğŸ› ï¸ Tecnologie Utilizzate

- **[Datapizza-AI](https://docs.datapizza.ai/)** - Framework GenAI modulare
- **[OpenAI](https://openai.com/)** - Embeddings (text-embedding-3-small) e LLM (gpt-4o-mini)
- **[Qdrant](https://qdrant.tech/)** - Vector database per similarity search
- **Python 3.13+** - Linguaggio di programmazione

## ğŸ“– Componenti Principali

### ingest_faq.py
Script che implementa la **IngestionPipeline** per:
- Leggere i file markdown delle FAQ
- Dividere il testo in chunks semantici
- Generare embeddings con OpenAI
- Salvare nel vector store Qdrant

### chatbot_faq.py
Implementa il chatbot usando **DagPipeline** con:
- Query rewriting per migliorare il retrieval
- Embedding della query
- Retrieval semantico dei chunks rilevanti
- Generazione risposta contestualizzata
- Fallback message quando non trova informazioni

## ğŸ”§ Configurazione Avanzata

### Parametri del Chatbot

Nel file `chatbot_faq.py` puoi modificare:

```python
# Numero di chunks da recuperare
k = 5

# Soglia minima di similarity score
score_threshold = 0.5

# Dimensione massima dei chunks
max_char = 1000
```

### Modelli Alternativi

Puoi sostituire i modelli OpenAI con alternative:

```python
# Per embeddings
embedder = OpenAIEmbedder(
    model_name="text-embedding-3-large"  # PiÃ¹ accurato
)

# Per generazione
client = OpenAIClient(
    model="gpt-4o"  # PiÃ¹ potente
)
```

## ğŸ› Troubleshooting

### "OPENAI_API_KEY non trovata"
â†’ Crea il file `.env` e inserisci la tua API key

### "Connection refused" (Qdrant)
â†’ Verifica che Qdrant sia in esecuzione: `docker ps | grep qdrant`

### "Collection not found"
â†’ Esegui prima l'ingestion: `python ingest_faq.py`

### Risposte sempre "Non sono ancora state fatte domande..."
â†’ Verifica che l'ingestion sia andata a buon fine
â†’ Prova ad abbassare la `score_threshold`

## ğŸ“š Risorse

- [Documentazione Datapizza-AI](https://docs.datapizza.ai/)
- [Guida RAG](https://docs.datapizza.ai/0.0.2/Guides/RAG/rag/)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)

## ğŸ¤ Contribuire

Questo Ã¨ un progetto di esempio. Sentiti libero di:
- Aggiungere nuove FAQ
- Migliorare i prompt
- Sperimentare con diversi modelli
- Estendere le funzionalitÃ 

## ğŸ“ Licenza

Progetto di esempio per dimostrare le capacitÃ  di Datapizza-AI.

## ğŸ‘¥ Autore

Progetto creato come esempio di utilizzo del framework [Datapizza-AI](https://github.com/datapizza-labs/datapizza-ai)
